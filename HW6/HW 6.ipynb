{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class lstm_model(nn.Module):\n",
    "    def __init__(self, vocab, hidden_size, num_layers, dropout=0.5):\n",
    "        super(lstm_model, self).__init__()\n",
    "        self.vocab = vocab  # 字符数据集\n",
    "        # 索引，字符\n",
    "        self.int_char = {i: char for i, char in enumerate(vocab)}\n",
    "        self.char_int = {char: i for i, char in self.int_char.items()}\n",
    "        # 对字符进行one-hot encoding\n",
    "        self.encoder = OneHotEncoder(sparse=True).fit(vocab.reshape(-1, 1))\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # lstm层\n",
    "        self.lstm = nn.LSTM(len(vocab), hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # 全连接层\n",
    "        self.linear = nn.Linear(hidden_size, len(vocab))\n",
    "\n",
    "    def forward(self, sequence, hs=None):\n",
    "        out, hs = self.lstm(sequence, hs)  # lstm的输出格式（batch_size, sequence_length, hidden_size）\n",
    "        out = out.reshape(-1, self.hidden_size)  # 这里需要将out转换为linear的输入格式，即（batch_size * sequence_length, hidden_size）\n",
    "        output = self.linear(out)  # linear的输出格式，(batch_size * sequence_length, vocab_size)\n",
    "        return output, hs\n",
    "\n",
    "    def onehot_encode(self, data):  # 对数据进行编码\n",
    "        return self.encoder.transform(data)\n",
    "\n",
    "    def onehot_decode(self, data):  # 对数据进行解码\n",
    "        return self.encoder.inverse_transform(data)\n",
    "\n",
    "    def label_encode(self, data):  # 对标签进行编码\n",
    "        return np.array([self.char_int[ch] for ch in data])\n",
    "\n",
    "    def label_decode(self, data):  # 对标签进行解码\n",
    "        return np.array([self.int_char[ch] for ch in data])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size, seq_len):\n",
    "    '''\n",
    "    :param data: 源数据，输入格式(num_samples, num_features)\n",
    "    :param batch_size: batch的大小\n",
    "    :param seq_len: 序列的长度（精度）\n",
    "    :return: （batch_size, seq_len, num_features）\n",
    "    '''\n",
    "    num_features = data.shape[1]\n",
    "    num_chars = batch_size * seq_len  # 一个batch_size的长度\n",
    "\n",
    "    num_batches = int(np.floor(data.shape[0] / num_chars))  # 计算出有多少个batches\n",
    "\n",
    "    need_chars = num_batches * num_chars  # 计算出需要的总字符量\n",
    "\n",
    "    targets = np.vstack((data[1:].A, data[0].A))  # 可能版本问题，取成numpy比较好reshape\n",
    "\n",
    "    inputs = data[:need_chars].A.astype(\"int\")  # 从原始数据data中截取所需的字符数量need_words\n",
    "    targets = targets[:need_chars]\n",
    "\n",
    "    targets = targets.reshape(batch_size, -1, num_features)\n",
    "    inputs = inputs.reshape(batch_size, -1, num_features)\n",
    "\n",
    "    for i in range(0, inputs.shape[1], seq_len):\n",
    "        x = inputs[:, i: i+seq_len]\n",
    "        y = targets[:, i: i+seq_len]\n",
    "        yield x, y  # 节省内存\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, batch_size, seq_len, epochs, lr=0.01, valid=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    model = model.to(device)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=lr,momentum=0.5)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if valid is not None:\n",
    "        data = model.onehot_encode(data.reshape(-1, 1))\n",
    "        valid = model.onehot_encode(valid.reshape(-1, 1))\n",
    "    else:\n",
    "        data = model.onehot_encode(data.reshape(-1, 1))\n",
    "\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        hs = None  # hs等于hidden_size隐藏层节点\n",
    "        train_ls = 0.0\n",
    "        val_ls = 0.0\n",
    "        for x, y in get_batches(data, batch_size, seq_len):\n",
    "            optimizer.zero_grad()\n",
    "            x = torch.tensor(x).float().to(device)\n",
    "            out, hs = model(x, hs)\n",
    "            hs = ([h.data for h in hs])\n",
    "            y = y.reshape(-1, len(model.vocab))\n",
    "            y = model.onehot_decode(y)\n",
    "            y = model.label_encode(y.squeeze())\n",
    "            y = torch.from_numpy(y).long().to(device)\n",
    "            loss = criterion(out, y.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_ls += loss.item()\n",
    "\n",
    "        if valid is not None:\n",
    "            model.eval()\n",
    "            hs = None\n",
    "            with torch.no_grad():\n",
    "                for x, y in get_batches(valid, batch_size, seq_len):\n",
    "                    x = torch.tensor(x).float().to(device)  # x为一组测试数据，包含batch_size * seq_len个字\n",
    "                    out, hs = model(x, hs)\n",
    "\n",
    "                    # out.shape输出为tensor[batch_size * seq_len, vocab_size]\n",
    "                    hs = ([h.data for h in hs])  # 更新参数\n",
    "\n",
    "                    y = y.reshape(-1, len(model.vocab))  # y.shape为(128,100,43)，因此需要转成两维，每行就代表一个字了，43为字典大小\n",
    "                    y = model.onehot_decode(y)  # y标签即为测试数据各个字的下一个字，进行one_hot解码，即变为字符\n",
    "                    # 但是此时y 是[[..],[..]]形式\n",
    "                    y = model.label_encode(y.squeeze())  # 因此需要去掉一维才能成功解码\n",
    "                    # 此时y为[12...]成为一维的数组，每个代表自己字典里对应字符的字典序\n",
    "                    y = torch.from_numpy(y).long().to(device)\n",
    "\n",
    "                    # 这里y和y.squeeze()出来的东西一样，可能这里没啥用，不太懂\n",
    "                    loss = criterion(out, y.squeeze())  # 计算损失值\n",
    "                    val_ls += loss.item()\n",
    "\n",
    "            val_loss.append(np.mean(val_ls))\n",
    "        train_loss.append(np.mean(train_ls))\n",
    "        print(\"train_loss:\", train_ls)\n",
    "\n",
    "    plt.plot(train_loss, label=\"train_loss\")\n",
    "    plt.plot(val_loss, label=\"val loss\")\n",
    "    plt.title(\"loop vs epoch\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    model_name = \"lstm_model.net\"\n",
    "\n",
    "    with open(model_name, 'wb') as f:  # 训练完了保存模型\n",
    "        torch.save(model.state_dict(), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, char, top_k=None, hidden_size=None):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model.to(device)\n",
    "    model.eval()  # 固定参数\n",
    "    with torch.no_grad():\n",
    "        char = np.array([char])  # 输入一个字符，预测下一个字是什么，先转成numpy\n",
    "        char = char.reshape(-1, 1)  # 变成二维才符合编码规范\n",
    "        char_encoding = model.onehot_encode(char).A  # 对char进行编码，取成numpy比较方便reshape\n",
    "        char_encoding = char_encoding.reshape(1, 1, -1)  # char_encoding.shape为(1, 1, 43)变成三维才符合模型输入格式\n",
    "        char_tensor = torch.tensor(char_encoding, dtype=torch.float32)  # 转成tensor\n",
    "        char_tensor = char_tensor.to(device)\n",
    "\n",
    "        out, hidden_size = model(char_tensor, hidden_size)  # 放入模型进行预测，out为结果\n",
    "\n",
    "        probs = F.softmax(out, dim=1).squeeze()  # 计算预测值,即所有字符的概率\n",
    "\n",
    "        if top_k is None:  # 选择概率最大的top_k个\n",
    "            indices = np.arange(vocab_size)\n",
    "        else:\n",
    "            probs, indices = probs.topk(top_k)\n",
    "            indices = indices.cpu().numpy()\n",
    "        probs = probs.cpu().numpy()\n",
    "\n",
    "        char_index = np.random.choice(indices, p=probs/probs.sum())  # 随机选择一个字符索引作为预测值\n",
    "        char = model.int_char[char_index]  # 通过索引找出预测字符\n",
    "\n",
    "    return char, hidden_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, length, top_k=None, sentence=\"c\"):\n",
    "    hidden_size = None\n",
    "    new_sentence = [char for char in sentence]\n",
    "    for i in range(length):\n",
    "        next_char, hidden_size = predict(model, new_sentence[-1], top_k=top_k, hidden_size=hidden_size)\n",
    "        new_sentence.append(next_char)\n",
    "    return \"\".join(new_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 17.488348722457886\n",
      "train_loss: 15.302414655685425\n",
      "train_loss: 14.863198280334473\n",
      "train_loss: 14.803853750228882\n",
      "train_loss: 14.772706508636475\n",
      "train_loss: 14.766765594482422\n",
      "train_loss: 14.745341300964355\n",
      "train_loss: 14.741189002990723\n",
      "train_loss: 14.733407735824585\n",
      "train_loss: 14.734067678451538\n",
      "train_loss: 14.731269121170044\n",
      "train_loss: 14.73129391670227\n",
      "train_loss: 14.730981349945068\n",
      "train_loss: 14.73002290725708\n",
      "train_loss: 14.730547428131104\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caaiatt taeie  iete   ita iatiti  i iiaeitie ete  teeea tat  t t i e  eeie  iea  ietiaa  i t  i ti it\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    hidden_size = 512\n",
    "    num_layers = 2\n",
    "    batch_size = 128\n",
    "    seq_len = 100\n",
    "    epochs = 15\n",
    "    lr = 0.01\n",
    "\n",
    "    f = pd.read_csv(\"dataset/dev.tsv\", sep=\"\\t\", header=None)\n",
    "    f = f[0]\n",
    "    text = list(f)\n",
    "    text = \".\".join(text)\n",
    "    vocab = np.array(sorted(set(text)))  # 建立字典\n",
    "    vocab_size = len(vocab)\n",
    "\n",
    "    val_len = int(np.floor(0.2 * len(text)))  # 划分训练测试集\n",
    "    trainset = np.array(list(text[:-val_len]))\n",
    "    validset = np.array(list(text[-val_len:]))\n",
    "\n",
    "    model = lstm_model(vocab, hidden_size, num_layers)  # 模型实例化\n",
    "    train(model, trainset, batch_size, seq_len, epochs, lr=lr, valid=validset)  # 训练模型\n",
    "    model.load_state_dict(torch.load(\"lstm_model.net\"))  # 调用保存的模型\n",
    "    new_text = sample(model, 100, top_k=5)  # 预测模型，生成100个字符,预测时选择概率最大的前5个\n",
    "    print(new_text)  # 输出预测文本\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
